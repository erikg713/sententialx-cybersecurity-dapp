# infra/docker/Dockerfile.prefetch
# Sentenial-X Model Prefetcher
# ----------------------------
# Builds a lightweight container to download and cache models ahead of runtime.
# Run this before deploying main services to ensure models are mounted locally.

FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Environment variables for Hugging Face / cache
ENV DEBIAN_FRONTEND=noninteractive
ENV HF_HOME=/opt/models
ENV TRANSFORMERS_CACHE=/opt/models
ENV HF_HUB_ENABLE_HF_TRANSFER=1
ENV PYTHONUNBUFFERED=1
ENV PATH="/opt/venv/bin:$PATH"

# Install Python + system deps
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-venv python3-pip git curl wget ca-certificates && \
    rm -rf /var/lib/apt/lists/*

# Create venv
RUN python3 -m venv /opt/venv
RUN pip install --upgrade pip

# Install Hugging Face tooling
RUN pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
RUN pip install transformers accelerate huggingface_hub sentencepiece safetensors

# Add prefetch script
WORKDIR /opt/prefetch
COPY prefetch_models.py /opt/prefetch/prefetch_models.py

# Default entrypoint: prefetch models
CMD ["python", "prefetch_models.py"]
